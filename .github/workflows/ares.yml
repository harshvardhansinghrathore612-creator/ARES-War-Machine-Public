name: ARES ‚Äì GitHub Safe Vulnerability Pipeline

on:
  workflow_dispatch:

jobs:
  security-hunt:
    runs-on: ubuntu-latest
    timeout-minutes: 350

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Clean previous data
      run: |
        rm -rf output *.zip || true
        mkdir -p output/{recon,probe,crawl/vulns/secrets,specialized}

    - name: Install core dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y python3-pip zip curl wget git ruby-full chromium chromium-driver xvfb libpcap-dev libxml2-dev libxslt1-dev
        echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

    - name: Install Go tools (GitHub-safe)
      run: |
        go install github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest
        go install github.com/tomnomnom/assetfinder@latest
        go install github.com/findomain/findomain@latest
        go install github.com/projectdiscovery/dnsx/cmd/dnsx@latest
        go install github.com/projectdiscovery/puredns/cmd/puredns@latest
        go install github.com/projectdiscovery/httpx/cmd/httpx@latest
        go install github.com/projectdiscovery/katana/cmd/katana@latest
        go install github.com/lc/gau/v2/cmd/gau@latest
        go install github.com/hahwul/dalfox/v2@latest
        go install github.com/projectdiscovery/nuclei/v2/cmd/nuclei@latest
        go install github.com/tomnomnom/waybackurls@latest
        go install github.com/hakluke/hakrawler@latest
        curl -LO https://github.com/hakluke/gospider/releases/latest/download/gospider-linux
        chmod +x gospider-linux
        sudo mv gospider-linux /usr/local/bin/gospider
        go install github.com/tomnomnom/qsreplace@latest
        go install github.com/tomnomnom/unfurl@latest
        go install github.com/tomnomnom/paramspider@latest
        go install github.com/Emoe/kxss@latest

    - name: Install Python tools
      run: |
        pip3 install trufflehog gitleaks detect-secrets secretfinder arjun paramspider \
                     trivy checkov tfsec prowler cloudsplaining s3scanner \
                     graphqlmap inql jwt_tool swagger-parser

    - name: Jaeles Signatures
      run: |
        jaeles config init
        git clone --depth 1 https://github.com/jaeles-project/jaeles-signatures.git $HOME/.jaeles/signatures-base || true

    - name: Create Google Drive uploader
      run: |
        cat << 'EOF' > drive_upload.py
        import os, sys
        from google.oauth2.credentials import Credentials
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaFileUpload

        def upload(file_path, folder_name):
            creds = Credentials(None,
                refresh_token=os.environ["GOOGLE_REFRESH_TOKEN"],
                token_uri="https://oauth2.googleapis.com/token",
                client_id=os.environ["GOOGLE_CLIENT_ID"],
                client_secret=os.environ["GOOGLE_CLIENT_SECRET"])
            service = build("drive", "v3", credentials=creds)

            query = f"name='{folder_name}' and '{os.environ['GDRIVE_FOLDER_ID']}' in parents and trashed=false"
            res = service.files().list(q=query).execute().get("files",[])
            if res:
                folder_id = res[0]["id"]
            else:
                folder = service.files().create(
                    body={"name": folder_name,
                          "mimeType":"application/vnd.google-apps.folder",
                          "parents":[os.environ["GDRIVE_FOLDER_ID"]]},
                    fields="id").execute()
                folder_id = folder["id"]

            media = MediaFileUpload(file_path)
            service.files().create(
                body={"name": os.path.basename(file_path),"parents":[folder_id]},
                media_body=media).execute()

        if __name__ == "__main__":
            upload(sys.argv[1], sys.argv[2])
        EOF

    - name: Run ARES pipeline
      env:
        GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
        GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
        GOOGLE_REFRESH_TOKEN: ${{ secrets.GOOGLE_REFRESH_TOKEN }}
        GDRIVE_FOLDER_ID: ${{ secrets.GDRIVE_FOLDER_ID }}
        TELEGRAM_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
        TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
      run: |
        TARGET=$(head -n 1 targets.txt)

        tg() {
          curl -s -X POST "https://api.telegram.org/bot$TELEGRAM_TOKEN/sendMessage" \
            -d chat_id="$TELEGRAM_CHAT_ID" \
            -d parse_mode="Markdown" \
            -d text="$1" >/dev/null
        }

        tg "üöÄ ARES started on $TARGET"

        ### STAGE 1: RECON
        tg "üîç Recon started"
        subfinder -d $TARGET -silent > output/recon/subs.txt || true
        assetfinder --subs-only $TARGET >> output/recon/subs.txt || true
        findomain -t $TARGET -q -o output/recon/findomain.txt || true
        dnsx -l output/recon/subs.txt -silent > output/recon/dnsx.txt || true
        puredns resolve output/recon/subs.txt -r /etc/resolv.conf -o output/recon/puredns.txt || true
        sort -u output/recon/subs.txt > output/recon/final_subs.txt
        zip -j recon.zip output/recon/*
        python3 drive_upload.py recon.zip Stage_1_Recon
        tg "‚úÖ Recon finished"

        ### STAGE 2: PROBING
        tg "üåê Probing started"
        httpx -l output/recon/final_subs.txt -silent > output/probe/live.txt || true
        zip -j probe.zip output/probe/*
        python3 drive_upload.py probe.zip Stage_2_Probe
        tg "‚úÖ Probing finished"

        ### STAGE 3: CRAWLING
        tg "üï∑ Crawling started"
        katana -l output/probe/live.txt -silent > output/crawl/katana.txt || true
        gau $TARGET >> output/crawl/gau.txt || true
        waybackurls $TARGET >> output/crawl/wayback.txt || true
        hakrawler -url $TARGET > output/crawl/hakrawler.txt || true
        gospider -s $TARGET -o output/crawl/gospider.txt || true
        zip -j crawl.zip output/crawl/*
        python3 drive_upload.py crawl.zip Stage_3_Crawl
        tg "‚úÖ Crawling finished"

        ### STAGE 4: PARAMS & XSS
        tg "‚ö° Parameter scan started"
        paramspider -d $TARGET -o output/crawl/params.txt || true
        arjun -u $TARGET -o output/crawl/arjun.txt || true
        unfurl -u $TARGET > output/crawl/unfurl.txt || true
        qsreplace -w output/crawl/params.txt > output/crawl/qsreplace.txt || true
        kxss -list output/crawl/params.txt > output/crawl/kxss.txt || true
        zip -j params.zip output/crawl/*
        python3 drive_upload.py params.zip Stage_4_Params
        tg "‚úÖ Parameter scan finished"

        ### STAGE 5: VULNS
        tg "üí• Vulnerability scan started"
        nuclei -l output/probe/live.txt -severity high,critical -o output/vulns/nuclei.txt || true
        dalfox file output/crawl/katana.txt --skip-bav -o output/vulns/dalfox.txt || true
        zip -j vulns.zip output/vulns/*
        python3 drive_upload.py vulns.zip Stage_5_Vulns
        tg "‚úÖ Vulnerability scan finished"

        ### STAGE 6: SECRETS
        tg "üîë Secrets scan started"
        trufflehog filesystem . > output/secrets/trufflehog.txt || true
        gitleaks detect --no-git -v > output/secrets/gitleaks.txt || true
        detect-secrets scan > output/secrets/detect_secrets.txt || true
        secretfinder -i . -o output/secrets/secretfinder.txt || true
        zip -j secrets.zip output/secrets/*
        python3 drive_upload.py secrets.zip Stage_6_Secrets
        tg "üèÅ ARES completed on $TARGET"
